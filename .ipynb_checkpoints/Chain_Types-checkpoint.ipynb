{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a484f6cc-4e1c-40a5-bdd0-c48ddb4ac6b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c8e6b6a0-9850-4f8c-ba35-07b2f7f0d89c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "chat_google=ChatGoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60b7848f-19fd-4944-9aa9-1f7fe2e472d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (0.0.5)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-openai) (0.1.22)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-openai) (1.24.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-openai) (1.12.0)\n",
      "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-openai) (0.5.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (6.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (3.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.0.88,>=0.0.87 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (0.0.87)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2022.7.9)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-openai) (2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\surya\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e60ef58-a75c-47ec-840d-6fecda3ff87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_google = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b3b2c941-3b0f-4137-83c9-163342435859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e11d2bbf-1e03-4704-80af-17a41597d7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = TextLoader(r\"D:\\Documents\\notepad_files\\LangChain_introduction.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "07f33310-ed8f-4f61-be9c-005769175e45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4ec6eb05-6107-4c3d-b608-14711066734f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='LangChain is an open-source framework designed to simplify the creation of applications sing large language models(LLMs). It provides a standard interface of chains, lots of integrations with other tools, and end-to-end chains for common applications.It allows AI developers to develop applications based on the combined Large Language Models (LLMs) such as GPT-4 with external sources of computation and data. This framework comes with a package for both Python and JavaScript.\\n\\nApplications of LangChain:\\n\\nLangChain is a powerful tool that can be used to build a wide range of LLM-powered applications.It is simple to use and has a large user and contributor community.\\n\\n1. Document analysis and summarization\\n2. Chatbots: LangChain can be used to build chatbots that interact with users naturally. For example, LangChain can be used to build a chatbot that can answer client questions, provide customer assistance, and even arrange appointments.\\n3. Code analysis: LangChain can be used to analyse code and find potential bugs or security flaws.\\nAnswering questions using sources: LangChain can be used to answer questions using a variety of sources, including text, code, and data. For example, LangChain can be used to answer questions about a specific topic by searching through a variety of sources, such as Wikipedia, news articles, and code repositories.\\n4. Data augmentation: LangChain can be used to augment data by generating new data that is similar to existing data. For example, LangChain can be used to generate new text data that is similar to existing text data. This can be useful for training machine learning models or for creating new datasets.\\n5. Text classification: LangChain can be used for text classifications and sentiment analysis with the text input data\\n6. Text summarization: LangChain can be used to summarize the text in the specified number of words or sentences.\\n7. Machine translation: LangChain can be used to translate the input text data into different languages.\\n\\nThe main properties of the LangChain network:\\n\\n1. Components: Components are modular building blocks that are ready and easy to use to build powerful applications. Components include LLM Wrappers, Prompt Template and Indexes for relevant information retrieval.\\n2. Chains: Chains allow us to combine multiple components together to solve a specific task. Chains make it easy for the implementation of complex applications by making it more modular and simple to debug and maintain.\\n3. Agents: Agents allow LLMs to interact with their environment. For example, using an external API to perform a specific action.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'D:\\\\Documents\\\\notepad_files\\\\LangChain_introduction.txt'})]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5240a17c-9b3e-485c-81d9-6485ef223706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter= RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=0)\n",
    "docs=text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2375354f-6b13-46ce-bea6-7f40f42f78cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d1ac1c82-f8fd-4720-9520-4504a7bfaee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Answering questions using sources: LangChain can be used to answer questions using a variety of sources, including text, code, and data. For example, LangChain can be used to answer questions about a specific topic by searching through a variety of sources, such as Wikipedia, news articles, and code repositories.', metadata={'source': 'D:\\\\Documents\\\\notepad_files\\\\LangChain_introduction.txt'})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b2a0f569-7750-40ad-85a6-9c5a07798482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ab31f5ed-f20d-4656-8bc2-d8e86b2292e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vector_db = Chroma.from_documents(documents=docs, embedding=embed_function, collection_name=\"langchain_google_db\", persist_directory=\"./langchain_google_vectorDB\")\n",
    "#vector_db.persist()\n",
    "vector_db = Chroma(collection_name=\"langchain_google_db\",persist_directory=\"./langchain_google_vectorDB\",embedding_function=embed_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3f6e0c57-8b63-4ebc-b590-df4e2e1d0584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vector_db = Chroma.from_documents(documents=docs, embedding=embed_function, collection_name=\"langchain_db\", persist_directory=\"./langchain_vectorDB\")\n",
    "#vector_db.persist()\n",
    "vector_db = Chroma(collection_name=\"langchain_google_db\",persist_directory=\"./langchain_vectorDB\",embedding_function=embed_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4fdfac21-b37f-4226-8f4c-e1d0fe97a7db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain=load_summarize_chain(llm=chat, chain_type='stuff', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cdd02348-0518-451d-a80f-a7746283a30d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain_google=load_summarize_chain(llm=chat_google, chain_type='stuff', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9beee956-4e44-4574-80c7-4139c9531c13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Answering questions using sources: LangChain can be used to answer questions using a variety of sources, including text, code, and data. For example, LangChain can be used to answer questions about a specific topic by searching through a variety of sources, such as Wikipedia, news articles, and code repositories.' metadata={'source': 'D:\\\\Documents\\\\notepad_files\\\\LangChain_introduction.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b2393c8-889c-4a72-8124-175588d5d80c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"LangChain is an open-source framework designed to simplify the creation of applications sing large language models(LLMs). It provides a standard interface of chains, lots of integrations with other tools, and end-to-end chains for common applications.It allows AI developers to develop applications based on the combined Large Language Models (LLMs) such as GPT-4 with external sources of computation\n",
      "\n",
      "and data. This framework comes with a package for both Python and JavaScript.\n",
      "\n",
      "Applications of LangChain:\n",
      "\n",
      "LangChain is a powerful tool that can be used to build a wide range of LLM-powered applications.It is simple to use and has a large user and contributor community.\n",
      "\n",
      "1. Document analysis and summarization\n",
      "2. Chatbots: LangChain can be used to build chatbots that interact with users naturally. For example, LangChain can be used to build a chatbot that can answer client questions, provide customer assistance, and even arrange appointments.\n",
      "3. Code analysis: LangChain can be used to analyse code and find potential bugs or security flaws.\n",
      "\n",
      "Answering questions using sources: LangChain can be used to answer questions using a variety of sources, including text, code, and data. For example, LangChain can be used to answer questions about a specific topic by searching through a variety of sources, such as Wikipedia, news articles, and code repositories.\n",
      "\n",
      "4. Data augmentation: LangChain can be used to augment data by generating new data that is similar to existing data. For example, LangChain can be used to generate new text data that is similar to existing text data. This can be useful for training machine learning models or for creating new datasets.\n",
      "\n",
      "5. Text classification: LangChain can be used for text classifications and sentiment analysis with the text input data\n",
      "6. Text summarization: LangChain can be used to summarize the text in the specified number of words or sentences.\n",
      "7. Machine translation: LangChain can be used to translate the input text data into different languages.\n",
      "\n",
      "The main properties of the LangChain network:\n",
      "\n",
      "1. Components: Components are modular building blocks that are ready and easy to use to build powerful applications. Components include LLM Wrappers, Prompt Template and Indexes for relevant information retrieval.\n",
      "\n",
      "2. Chains: Chains allow us to combine multiple components together to solve a specific task. Chains make it easy for the implementation of complex applications by making it more modular and simple to debug and maintain.\n",
      "3. Agents: Agents allow LLMs to interact with their environment. For example, using an external API to perform a specific action.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "891f8779-83c6-4892-8218-84f219d4bc3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"LangChain is an open-source framework designed to simplify the creation of applications sing large language models(LLMs). It provides a standard interface of chains, lots of integrations with other tools, and end-to-end chains for common applications.It allows AI developers to develop applications based on the combined Large Language Models (LLMs) such as GPT-4 with external sources of computation\n",
      "\n",
      "and data. This framework comes with a package for both Python and JavaScript.\n",
      "\n",
      "Applications of LangChain:\n",
      "\n",
      "LangChain is a powerful tool that can be used to build a wide range of LLM-powered applications.It is simple to use and has a large user and contributor community.\n",
      "\n",
      "1. Document analysis and summarization\n",
      "2. Chatbots: LangChain can be used to build chatbots that interact with users naturally. For example, LangChain can be used to build a chatbot that can answer client questions, provide customer assistance, and even arrange appointments.\n",
      "3. Code analysis: LangChain can be used to analyse code and find potential bugs or security flaws.\n",
      "\n",
      "Answering questions using sources: LangChain can be used to answer questions using a variety of sources, including text, code, and data. For example, LangChain can be used to answer questions about a specific topic by searching through a variety of sources, such as Wikipedia, news articles, and code repositories.\n",
      "\n",
      "4. Data augmentation: LangChain can be used to augment data by generating new data that is similar to existing data. For example, LangChain can be used to generate new text data that is similar to existing text data. This can be useful for training machine learning models or for creating new datasets.\n",
      "\n",
      "5. Text classification: LangChain can be used for text classifications and sentiment analysis with the text input data\n",
      "6. Text summarization: LangChain can be used to summarize the text in the specified number of words or sentences.\n",
      "7. Machine translation: LangChain can be used to translate the input text data into different languages.\n",
      "\n",
      "The main properties of the LangChain network:\n",
      "\n",
      "1. Components: Components are modular building blocks that are ready and easy to use to build powerful applications. Components include LLM Wrappers, Prompt Template and Indexes for relevant information retrieval.\n",
      "\n",
      "2. Chains: Chains allow us to combine multiple components together to solve a specific task. Chains make it easy for the implementation of complex applications by making it more modular and simple to debug and maintain.\n",
      "3. Agents: Agents allow LLMs to interact with their environment. For example, using an external API to perform a specific action.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result_google = chain_google.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d463ad16-6aa4-4641-b9fa-dacca67b104e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework that simplifies the creation of applications using large language models (LLMs). It provides a standard interface, integrations with other tools, and end-to-end chains for common applications. LangChain allows AI developers to build applications based on combined LLMs like GPT-4 with external computation and data sources. It can be used for document analysis, chatbots, code analysis, answering questions using various sources, data augmentation, text classification, text summarization, and machine translation. LangChain's main properties include modular components, chains for combining components, and agents for LLM interaction with the environment.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2706c941-92cc-4962-97b9-1f7f8a766d95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework that simplifies the creation of applications using LLMs. It provides a standard interface, integrations, and end-to-end chains for common applications. LangChain has applications in document analysis, summarization, chatbots, code analysis, question answering, data augmentation, text classification, summarization, and machine translation. It utilizes components, chains, and agents to build modular and easy-to-debug applications. LangChain offers a package for both Python and JavaScript and has a large user and contributor community.\n"
     ]
    }
   ],
   "source": [
    "print(result_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a2f74-4e76-4cfb-8adf-1ec7de5367f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb572d5-8a39-4667-ad73-3eed0104e1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8539f33-08b8-410f-8df1-ab6c4163a287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b0b3a-a9ac-4257-bf1e-d274b3e8b723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939db94-3d9c-4768-ad80-c0fe8e777046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852740c1-712b-437a-941e-d37aab4cac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42113833-9f43-442d-81b6-a5932c8bd674",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who got permission to use IBM 1401 computer?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa671d0-ed78-4701-a345-a9bc3c550f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: Symatic Similarity Search\n",
    "\n",
    "result = vector_db.similarity_search(query=query, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04c3c8d-18be-4c91-a185-d66c58b04142",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a117d9-501c-4dec-a920-590c18f9992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2: Maximum Marginal Relevance (MMR)\n",
    "#fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
    "#k: Number of Documents to return\n",
    "\n",
    "result = vector_db.max_marginal_relevance_search(query=query, fetch_k=4, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f838f3-122d-4c8c-9fd7-7403235ad4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef2aea-ea42-4902-aede-0438b0e1d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3: Contextual Compression Retriever\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba91cdc-4bc9-49b1-9eb6-b0dbd4aed2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = LLMChainExtractor.from_llm(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12236c80-48ff-4076-bcb6-cfed79422c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=vector_db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39975af7-b37e-46f7-af0f-4778d99db9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=compression_retriever.get_relevant_documents(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7110f3d6-f93b-4aee-ac13-e65962217d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89191b4-2b21-41b0-a6f9-e60cde3e727a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736e2918-1bdc-42ef-a1a8-333b589b33f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4: RetrievalQA with map_reduce, chain type\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e5f17-41dd-4e14-82be-eb82de98a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "question_prompt = ChatPromptTemplate.from_template(\n",
    "    template=question_template)\n",
    "\n",
    "combine_template = \"Write a summary of the following text:\\n\\n{summaries}\"\n",
    "combine_prompt = ChatPromptTemplate.from_template(\n",
    "    template=combine_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e40eec-bc68-4011-9b7b-7a3f25231300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=chat, chain_type=\"map_reduce\", \n",
    "                                       retriever=vector_db.as_retriever(search_kwargs={'fetch_k': 4, 'k': 3}, search_type='mmr'), \n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"question_prompt\":question_prompt, \"combine_prompt\":combine_prompt},\n",
    "                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a4f940-24ee-4e08-b01c-1b1d242d6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=qa_chain({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eae772-36ce-4168-a7a4-10bb68c93466",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (result['result'])\n",
    "print (result['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea51dc70-b7eb-414f-b1d0-6fe3c8303e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08c6c0-555b-4a22-86f0-e59b156048e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5: RetrievalQA with refine, chain type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7895d-7db8-4162-ac10-a2251c943fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=chat, chain_type=\"refine\", \n",
    "                                       retriever=vector_db.as_retriever(), \n",
    "                                       return_source_documents=True,\n",
    "                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08fb8b-cea8-4765-a0cb-e07b7ff33ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbbf18-a1c7-456d-b2a4-232162e5e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (result['result'])\n",
    "print (result['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa6b2d8-5515-416a-b984-d9d859744c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf94ba8-557b-4c40-8875-480e6a671d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=chat, chain_type=\"map_rerank\", \n",
    "                                       retriever=vector_db.as_retriever(), \n",
    "                                       return_source_documents=True,\n",
    "                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a2c54-5bfe-41ca-aa8b-52b669749e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ff665-0e63-4008-938d-850d22346103",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (result['result'])\n",
    "print (result['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4f2d2-f092-419e-8f69-438d97470c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
